{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import Sequential, Input, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from bayes_opt import BayesianOptimization, SequentialDomainReductionTransformer\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import run_models, output, process_df\n",
    "from run_models import create_and_fit_regression_rf, create_and_fit_regression_lgb, create_and_fit_regression_nn, create_regression_lgb, build_nn_model, get_regression_cv_metrics, get_regression_cv_predictions\n",
    "from output import output_metrics, print_train_history, print_metrics, print_graphs, print_formatted, print_output, print_formatted_params\n",
    "from process_df import split_df\n",
    "reload(run_models)\n",
    "reload(output)\n",
    "reload(process_df)\n",
    "from run_models import create_and_fit_regression_rf, create_and_fit_regression_lgb, create_and_fit_regression_nn, create_regression_lgb, build_nn_model, get_regression_cv_metrics, get_regression_cv_predictions\n",
    "from output import output_metrics, print_train_history, print_metrics, print_graphs, print_formatted, print_output, print_formatted_params\n",
    "from process_df import split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [ 'tag__murder',\n",
    " 'tag__violence',\n",
    " 'tag__flashback',\n",
    " 'tag__romantic',\n",
    " 'tag__cult',\n",
    " 'tag__revenge',\n",
    " 'tag__psychedelic',\n",
    " 'tag__comedy',\n",
    " 'tag__suspenseful',\n",
    " 'tag__good_versus_evil',\n",
    " 'tag__humor',\n",
    " 'tag__entertaining',\n",
    " 'tag__neo_noir',\n",
    " 'tag__action',\n",
    " 'tag__boring',\n",
    " 'tag__other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'outliers/final/df'\n",
    "# with open(f'{name}_data.pickle', 'rb') as handle:\n",
    "#     data = pickle.load(handle)\n",
    "\n",
    "# X_train, y_train, X_val, y_val, X_test, y_test = data['X_train'], data['y_train'], data['X_val'], data['y_val'], data['X_test'], data['y_test']\n",
    "# X = pd.concat([X_train, X_test, X_val])\n",
    "# y = np.concatenate([y_train, y_test, y_val])\n",
    "\n",
    "# with open(f'{name}_process.pickle', 'rb') as handle:\n",
    "#     process = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('outliers/final/df.csv', index_col='id')\n",
    "\n",
    "# def get_df_work_columns(df, df_columns):\n",
    "#     return df[[col for col in df_columns if not 'META' in col or col == 'META__revenue']]\n",
    "\n",
    "# df = get_df_work_columns(df, df)\n",
    "\n",
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputer = KNNImputer(n_neighbors=30, weights='distance')\n",
    "# nan_filled = df.copy()\n",
    "# nan_filled[:] = imputer.fit_transform(df)\n",
    "\n",
    "# nan_filled.to_csv(f'outliers/final/nan_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = pd.read_csv(f'outliers/final/df.csv', index_col='id')\n",
    "# cols = [c for c in dd.columns if not 'META' in c or 'revenue' in c]\n",
    "# just_split_data = split_df(dd[cols])\n",
    "# with open(f'outliers/final/df_raw_data.pickle', 'wb') as handle:\n",
    "#     pickle.dump(just_split_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('outliers/final/df.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values = {}\n",
    "# df_len = df.shape[0]\n",
    "# for c in df.columns:\n",
    "#     if 'META__' not in c:\n",
    "#         len_missing = len([i for i in df[c] if pd.isna(i)])\n",
    "#         if len_missing:\n",
    "#             missing_values[c] = [len_missing, len_missing/df_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_miss = {k: v[1] for k, v in sorted(missing_values.items(), key=lambda item: item[1][1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20,20))\n",
    "# label = list(sorted_miss.keys())\n",
    "# values = list(sorted_miss.values())\n",
    "# ax.barh(label, values)\n",
    "# for i in range(len(values)):\n",
    "#     plt.text(values[i] + 0.01, i, round(values[i], 2))\n",
    "# ax.set_xlabel('Percentage of missing data')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([c for c in X.columns if 'tag' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for t in [c for c in X.columns if 'tag' in c]:\n",
    "# for t in tags:\n",
    "#     print('\\t\\t\\t\\\\item',t.replace('_', '\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'outliers/final/nan_filled_data.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data['X_train'], data['y_train'], data['X_val'], data['y_val'], data['X_test'], data['y_test']\n",
    "X = pd.concat([X_train, X_test, X_val])\n",
    "# X = X[[c for c in X.columns if 'tag' not in c or c in tags]]\n",
    "y = np.concatenate([y_train, y_test, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune with bayes optimizator\n",
    "def bayes_parameter_opt_nn_regression(X, y, init_round=15, opt_round=30, n_folds=10, patience=10, validation_size=0.05, verbose=0):\n",
    "    def nn_eval(**params_raw):\n",
    "        params = convert_nn_params(params_raw)\n",
    "        print(params)\n",
    "        cv_result = get_regression_cv_metrics(create_and_fit_nn_regressor_with_params, X, y,\n",
    "            n_splits=n_folds, patience=patience, validation_size=validation_size, regressor_params=params, verbose=verbose)\n",
    "        return -cv_result['cv_metrics']['smape']\n",
    "\n",
    "    pbounds = {\n",
    "        'adamax_learning_rate': (0.0005, 0.1),\n",
    "        # 'adamax_beta_1': (0.8, 1),\n",
    "        # 'adamax_beta_2': (0.95, 1),\n",
    "        # 'batch_size': (4, 1024),\n",
    "    }\n",
    "    for l in range(1, 3):\n",
    "        pbounds[f'l{l}_neurons'] = (64, 1024)\n",
    "        pbounds[f'l{l}_activation'] = (0, 4)\n",
    "        pbounds[f'l{l}_kernel_regularizer_l1'] = (0, 0.05)\n",
    "        pbounds[f'l{l}_kernel_regularizer_l2'] = (0, 0.05)\n",
    "        pbounds[f'l{l}_dropout'] = (0.1, 0.8)\n",
    "\n",
    "    bounds_transformer = SequentialDomainReductionTransformer()\n",
    "    optimizer = BayesianOptimization(\n",
    "        f = nn_eval, \n",
    "        pbounds = pbounds,\n",
    "        random_state=0,\n",
    "        bounds_transformer=bounds_transformer,\n",
    "    )\n",
    "    optimizer.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    model_params=[]\n",
    "    for model in range(len(optimizer.res)):\n",
    "        model_params.append(optimizer.res[model]['target'])\n",
    "    return {\n",
    "        'target': optimizer.res[pd.Series(model_params).idxmax()]['target'], \n",
    "        'params': optimizer.res[pd.Series(model_params).idxmax()]['params'],\n",
    "        'bounds_transformer': bounds_transformer,\n",
    "        'optimizer': optimizer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_formatted(obj):\n",
    "    for p in obj:\n",
    "        val = obj[p]\n",
    "        if isinstance(val, float):\n",
    "            val = round(val, 3)\n",
    "        elif isinstance(val, str):\n",
    "            val = f'\\'{val}\\''\n",
    "        print(f'{p}={val},')\n",
    "\n",
    "def print_output(obj):\n",
    "    for p in obj:\n",
    "        print(f'{p}: {round(obj[p],3)}')\n",
    "   \n",
    "def print_formatted_params(params):\n",
    "    print_formatted(convert_nn_params(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_fit_nn_regressor_with_params(X, y, X_val=None, y_val=None, patience=30, regressor_params={}, verbose=0, validation_split=None):\n",
    "    start = time.time()\n",
    "    fit_params = {\n",
    "        'model__epochs': 10000,\n",
    "        'model__shuffle': True,\n",
    "        'model__use_multiprocessing': True,\n",
    "        'model__verbose': verbose,\n",
    "        # 'model__batch_size': regressor_params.pop('batch_size'),\n",
    "        'model__batch_size': 16,\n",
    "        # 'model__batch_size': X.shape[0],\n",
    "        'model__callbacks': [EarlyStopping(monitor='val_keras_mape', mode='min', verbose=1, patience=patience)],\n",
    "    }\n",
    "    if X_val is None and y_val is None:\n",
    "        fit_params['model__validation_split']=validation_split\n",
    "    else:\n",
    "        fit_params['model__validation_data']=(X_val, y_val)\n",
    "    model = TransformedTargetRegressor(\n",
    "        Pipeline([\n",
    "            ('powertransform', PowerTransformer()),\n",
    "            ('model', KerasRegressor(build_nn_model_with_params([X.shape[1]], regressor_params))),\n",
    "        ]),\n",
    "        PowerTransformer(),\n",
    "    ).fit(X, y, **fit_params)\n",
    "    end = time.time()\n",
    "    print(f'model fit time: {end - start}')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_nn_model_with_params(input_shape, params):\n",
    "    # def get_model():\n",
    "    #     # adamax = Adamax(, beta_1=params['adamax_beta_1'], beta_2=params['adamax_beta_2'])\n",
    "    #     adamax = Adamax(learning_rate=params['adamax_learning_rate'], beta_1=0.958, beta_2=0.987)\n",
    "    #     hidden_layers = []\n",
    "    #     for l in range(1, 3):\n",
    "    #         hidden_layers.append(Dense(\n",
    "    #             params[f'l{l}_neurons'],\n",
    "    #             activation=params[f'l{l}_activation'],\n",
    "    #             # kernel_regularizer=l1_l2(l1=params[f'l{l}_kernel_regularizer_l1'], l2=params[f'l{l}_kernel_regularizer_l2']),\n",
    "    #             name=f'Dense_{l}',\n",
    "    #         ))\n",
    "    #         hidden_layers.append(Dropout(params[f'l{l}_dropout'], name=f'Dropout_{l}'))\n",
    "        \n",
    "    #     input_layer = Input(input_shape)\n",
    "    #     output_layer = Dense(1, name='Output')\n",
    "    #     model = Sequential([input_layer] + hidden_layers + [output_layer])\n",
    "\n",
    "    #     model.compile(\n",
    "    #         loss=losses.MeanSquaredError(),\n",
    "    #         optimizer=adamax, \n",
    "    #         metrics=['mae', 'mse', 'mape'],\n",
    "    #     )\n",
    "    #     return model\n",
    "    # return get_model\n",
    "    def keras_wape(y_true, y_pred):\n",
    "        if not tf.is_tensor(y_pred):\n",
    "            y_pred = K.constant(y_pred)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        return 100*K.sum(K.abs(y_pred - y_true)) / K.constant(y_true.shape[1])\n",
    "\n",
    "    def keras_mape(y_true, y_pred):\n",
    "        if not tf.is_tensor(y_pred):\n",
    "            y_pred = K.constant(y_pred)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        return 100. * K.mean(K.abs((y_true - y_pred) / K.clip(K.abs(y_true),K.epsilon(),None)), axis=-1)\n",
    "\n",
    "    def get_model():\n",
    "        adamax = Adamax(learning_rate=0.001,beta_1=0.958,beta_2=0.987)\n",
    "        model = Sequential([\n",
    "            Dense(\n",
    "                256, \n",
    "                activation='sigmoid', \n",
    "                input_shape=input_shape,\n",
    "                kernel_initializer='glorot_normal',\n",
    "                # kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001),\n",
    "                # bias_regularizer=l1_l2(l1=0.001, l2=0.1)\n",
    "            ),\n",
    "            Dropout(0.1),\n",
    "            Dense(\n",
    "                256, \n",
    "                activation='sigmoid',\n",
    "                kernel_initializer='glorot_normal',\n",
    "                # kernel_regularizer=l1_l2(l1=0, l2=0.001),\n",
    "                # bias_regularizer=l1_l2(l1=0.01, l2=0.01),\n",
    "            ),\n",
    "            Dropout(0.5),\n",
    "            Dense(1, kernel_initializer='glorot_normal')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            loss=losses.MeanSquaredError(),\n",
    "            # loss=losses.MeanSquaredLogarithmicError(),\n",
    "            # loss=losses.MeanAbsolutePercentageError(),\n",
    "            # loss=losses.MeanAbsoluteError(),\n",
    "            # loss=losses.CosineSimilarity(),\n",
    "            # loss=losses.Huber(),\n",
    "            # loss=losses.LogCosh(),\n",
    "            optimizer=adamax,\n",
    "            metrics=['mae', 'mse', keras_mape, keras_wape],\n",
    "        )\n",
    "        return model\n",
    "    return get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "poch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3124 - mae: 0.4367 - mse: 0.3124 - keras_mape: 279.7160 - keras_wmape: 697.1483 - val_loss: 0.2734 - val_mae: 0.4034 - val_mse: 0.2734 - val_keras_mape: 207.8055 - val_keras_wmape: 633.3179\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2950 - mae: 0.4245 - mse: 0.2950 - keras_mape: 216.3272 - keras_wmape: 677.5938 - val_loss: 0.2778 - val_mae: 0.4084 - val_mse: 0.2778 - val_keras_mape: 210.6471 - val_keras_wmape: 641.1518\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2830 - mae: 0.4123 - mse: 0.2830 - keras_mape: 233.6386 - keras_wmape: 658.1544 - val_loss: 0.2650 - val_mae: 0.3887 - val_mse: 0.2650 - val_keras_mape: 183.2258 - val_keras_wmape: 610.2578\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2798 - mae: 0.4101 - mse: 0.2798 - keras_mape: 220.5184 - keras_wmape: 654.6483 - val_loss: 0.2683 - val_mae: 0.3950 - val_mse: 0.2683 - val_keras_mape: 197.7003 - val_keras_wmape: 620.2054\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2770 - mae: 0.4075 - mse: 0.2770 - keras_mape: 223.0718 - keras_wmape: 650.5436 - val_loss: 0.2626 - val_mae: 0.3845 - val_mse: 0.2626 - val_keras_mape: 187.5163 - val_keras_wmape: 603.7153\n",
      "Epoch 8/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2668 - mae: 0.4002 - mse: 0.2668 - keras_mape: 220.8541 - keras_wmape: 638.8343 - val_loss: 0.2603 - val_mae: 0.3797 - val_mse: 0.2603 - val_keras_mape: 177.5415 - val_keras_wmape: 596.1312\n",
      "Epoch 9/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2646 - mae: 0.3974 - mse: 0.2646 - keras_mape: 216.5764 - keras_wmape: 634.2985 - val_loss: 0.2626 - val_mae: 0.3887 - val_mse: 0.2626 - val_keras_mape: 198.3378 - val_keras_wmape: 610.1896\n",
      "Epoch 10/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2621 - mae: 0.3946 - mse: 0.2621 - keras_mape: 236.0027 - keras_wmape: 629.8860 - val_loss: 0.2777 - val_mae: 0.4003 - val_mse: 0.2777 - val_keras_mape: 217.4230 - val_keras_wmape: 628.4903\n",
      "Epoch 11/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2589 - mae: 0.3933 - mse: 0.2589 - keras_mape: 231.6456 - keras_wmape: 627.7900 - val_loss: 0.2596 - val_mae: 0.3806 - val_mse: 0.2596 - val_keras_mape: 187.3502 - val_keras_wmape: 597.5012\n",
      "Epoch 12/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2560 - mae: 0.3886 - mse: 0.2560 - keras_mape: 213.9750 - keras_wmape: 620.3392 - val_loss: 0.2807 - val_mae: 0.4044 - val_mse: 0.2807 - val_keras_mape: 212.8649 - val_keras_wmape: 634.8743\n",
      "Epoch 13/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2504 - mae: 0.3860 - mse: 0.2504 - keras_mape: 228.1367 - keras_wmape: 616.0754 - val_loss: 0.2784 - val_mae: 0.4002 - val_mse: 0.2784 - val_keras_mape: 210.0595 - val_keras_wmape: 628.2595\n",
      "Epoch 00013: early stopping\n",
      "model fit time: 10.685550928115845\n",
      "split 6\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.5914 - mae: 0.6003 - mse: 0.5914 - keras_mape: 260.2910 - keras_wmape: 958.4043 - val_loss: 0.2934 - val_mae: 0.4181 - val_mse: 0.2934 - val_keras_mape: 3266.8926 - val_keras_wmape: 656.4927\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3408 - mae: 0.4561 - mse: 0.3408 - keras_mape: 227.8915 - keras_wmape: 728.0925 - val_loss: 0.2765 - val_mae: 0.4093 - val_mse: 0.2765 - val_keras_mape: 4014.9553 - val_keras_wmape: 642.5403\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3122 - mae: 0.4366 - mse: 0.3122 - keras_mape: 221.7522 - keras_wmape: 697.0226 - val_loss: 0.2700 - val_mae: 0.4014 - val_mse: 0.2700 - val_keras_mape: 4560.6143 - val_keras_wmape: 630.1246\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2963 - mae: 0.4232 - mse: 0.2963 - keras_mape: 220.9483 - keras_wmape: 675.6718 - val_loss: 0.2640 - val_mae: 0.3892 - val_mse: 0.2640 - val_keras_mape: 3461.7039 - val_keras_wmape: 611.0833\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2817 - mae: 0.4122 - mse: 0.2817 - keras_mape: 215.1971 - keras_wmape: 658.1521 - val_loss: 0.2691 - val_mae: 0.3980 - val_mse: 0.2691 - val_keras_mape: 3850.4058 - val_keras_wmape: 624.8844\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2757 - mae: 0.4063 - mse: 0.2757 - keras_mape: 212.2686 - keras_wmape: 648.7189 - val_loss: 0.2648 - val_mae: 0.3919 - val_mse: 0.2648 - val_keras_mape: 3765.2456 - val_keras_wmape: 615.3550\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 5.883486270904541\n",
      "split 7\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.5697 - mae: 0.5866 - mse: 0.5697 - keras_mape: 301.3182 - keras_wmape: 936.4550 - val_loss: 0.2871 - val_mae: 0.4132 - val_mse: 0.2871 - val_keras_mape: 204.9675 - val_keras_wmape: 648.7400\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3395 - mae: 0.4574 - mse: 0.3395 - keras_mape: 226.7992 - keras_wmape: 730.2888 - val_loss: 0.2762 - val_mae: 0.4098 - val_mse: 0.2762 - val_keras_mape: 209.4662 - val_keras_wmape: 643.3741\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3084 - mae: 0.4325 - mse: 0.3084 - keras_mape: 232.4877 - keras_wmape: 690.5378 - val_loss: 0.2651 - val_mae: 0.3961 - val_mse: 0.2651 - val_keras_mape: 201.6469 - val_keras_wmape: 621.8354\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2959 - mae: 0.4222 - mse: 0.2959 - keras_mape: 221.7042 - keras_wmape: 673.9830 - val_loss: 0.2686 - val_mae: 0.3981 - val_mse: 0.2686 - val_keras_mape: 190.9611 - val_keras_wmape: 624.9537\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2851 - mae: 0.4145 - mse: 0.2851 - keras_mape: 203.4991 - keras_wmape: 661.7285 - val_loss: 0.2690 - val_mae: 0.3982 - val_mse: 0.2690 - val_keras_mape: 191.9226 - val_keras_wmape: 625.2173\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2789 - mae: 0.4098 - mse: 0.2789 - keras_mape: 207.2198 - keras_wmape: 654.3173 - val_loss: 0.2733 - val_mae: 0.3998 - val_mse: 0.2733 - val_keras_mape: 204.8533 - val_keras_wmape: 627.6323\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2733 - mae: 0.4057 - mse: 0.2733 - keras_mape: 206.2517 - keras_wmape: 647.6844 - val_loss: 0.2619 - val_mae: 0.3856 - val_mse: 0.2619 - val_keras_mape: 182.3430 - val_keras_wmape: 605.3959\n",
      "Epoch 8/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2690 - mae: 0.4028 - mse: 0.2690 - keras_mape: 211.3584 - keras_wmape: 643.1490 - val_loss: 0.2638 - val_mae: 0.3876 - val_mse: 0.2638 - val_keras_mape: 194.6877 - val_keras_wmape: 608.4579\n",
      "Epoch 9/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2648 - mae: 0.3977 - mse: 0.2648 - keras_mape: 200.3242 - keras_wmape: 634.8836 - val_loss: 0.2646 - val_mae: 0.3841 - val_mse: 0.2646 - val_keras_mape: 183.9420 - val_keras_wmape: 603.1135\n",
      "Epoch 10/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2599 - mae: 0.3927 - mse: 0.2599 - keras_mape: 197.6930 - keras_wmape: 626.8882 - val_loss: 0.2625 - val_mae: 0.3811 - val_mse: 0.2625 - val_keras_mape: 180.9056 - val_keras_wmape: 598.2929\n",
      "Epoch 11/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2592 - mae: 0.3939 - mse: 0.2592 - keras_mape: 210.7110 - keras_wmape: 628.8228 - val_loss: 0.2636 - val_mae: 0.3854 - val_mse: 0.2636 - val_keras_mape: 189.2982 - val_keras_wmape: 605.1475\n",
      "Epoch 12/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2529 - mae: 0.3877 - mse: 0.2529 - keras_mape: 206.0309 - keras_wmape: 618.9476 - val_loss: 0.2652 - val_mae: 0.3864 - val_mse: 0.2652 - val_keras_mape: 194.0625 - val_keras_wmape: 606.6293\n",
      "Epoch 13/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2489 - mae: 0.3839 - mse: 0.2489 - keras_mape: 199.0371 - keras_wmape: 612.9498 - val_loss: 0.2615 - val_mae: 0.3816 - val_mse: 0.2615 - val_keras_mape: 187.0420 - val_keras_wmape: 599.0682\n",
      "Epoch 14/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2494 - mae: 0.3814 - mse: 0.2494 - keras_mape: 197.7237 - keras_wmape: 608.9582 - val_loss: 0.2766 - val_mae: 0.4046 - val_mse: 0.2766 - val_keras_mape: 188.9607 - val_keras_wmape: 635.2037\n",
      "Epoch 15/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2458 - mae: 0.3810 - mse: 0.2458 - keras_mape: 203.7735 - keras_wmape: 608.2554 - val_loss: 0.2602 - val_mae: 0.3819 - val_mse: 0.2602 - val_keras_mape: 187.5303 - val_keras_wmape: 599.6147\n",
      "Epoch 00015: early stopping\n",
      "model fit time: 11.40432596206665\n",
      "split 8\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.5926 - mae: 0.5979 - mse: 0.5926 - keras_mape: 1027.4526 - keras_wmape: 954.5052 - val_loss: 0.2892 - val_mae: 0.4214 - val_mse: 0.2892 - val_keras_mape: 260.8224 - val_keras_wmape: 661.5488\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.3372 - mae: 0.4530 - mse: 0.3372 - keras_mape: 1053.5864 - keras_wmape: 723.2482 - val_loss: 0.2797 - val_mae: 0.3938 - val_mse: 0.2797 - val_keras_mape: 197.8047 - val_keras_wmape: 618.1899\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3037 - mae: 0.4294 - mse: 0.3037 - keras_mape: 695.8692 - keras_wmape: 685.6107 - val_loss: 0.2648 - val_mae: 0.3929 - val_mse: 0.2648 - val_keras_mape: 214.3519 - val_keras_wmape: 616.8831\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2908 - mae: 0.4197 - mse: 0.2908 - keras_mape: 839.9052 - keras_wmape: 670.0847 - val_loss: 0.2630 - val_mae: 0.3892 - val_mse: 0.2630 - val_keras_mape: 211.0020 - val_keras_wmape: 611.0999\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2802 - mae: 0.4105 - mse: 0.2802 - keras_mape: 689.4276 - keras_wmape: 655.4055 - val_loss: 0.2659 - val_mae: 0.3938 - val_mse: 0.2659 - val_keras_mape: 220.8664 - val_keras_wmape: 618.2695\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2756 - mae: 0.4061 - mse: 0.2756 - keras_mape: 974.9117 - keras_wmape: 648.4213 - val_loss: 0.2762 - val_mae: 0.4045 - val_mse: 0.2762 - val_keras_mape: 221.8949 - val_keras_wmape: 635.1377\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2696 - mae: 0.4001 - mse: 0.2696 - keras_mape: 941.4363 - keras_wmape: 638.8255 - val_loss: 0.2656 - val_mae: 0.3928 - val_mse: 0.2656 - val_keras_mape: 222.4738 - val_keras_wmape: 616.6580\n",
      "Epoch 00007: early stopping\n",
      "model fit time: 5.523204326629639\n",
      "split 9\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.5635 - mae: 0.5864 - mse: 0.5635 - keras_mape: 469.9322 - keras_wmape: 936.2604 - val_loss: 0.2942 - val_mae: 0.4284 - val_mse: 0.2942 - val_keras_mape: 385.8472 - val_keras_wmape: 672.5565\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3368 - mae: 0.4526 - mse: 0.3368 - keras_mape: 298.3705 - keras_wmape: 722.5270 - val_loss: 0.2713 - val_mae: 0.3893 - val_mse: 0.2713 - val_keras_mape: 299.2098 - val_keras_wmape: 611.1609\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3034 - mae: 0.4294 - mse: 0.3034 - keras_mape: 300.2703 - keras_wmape: 685.6169 - val_loss: 0.2611 - val_mae: 0.3907 - val_mse: 0.2611 - val_keras_mape: 306.7888 - val_keras_wmape: 613.4415\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2887 - mae: 0.4178 - mse: 0.2887 - keras_mape: 259.2932 - keras_wmape: 667.0907 - val_loss: 0.2568 - val_mae: 0.3852 - val_mse: 0.2568 - val_keras_mape: 299.9554 - val_keras_wmape: 604.7597\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2759 - mae: 0.4074 - mse: 0.2759 - keras_mape: 292.5098 - keras_wmape: 650.3931 - val_loss: 0.2623 - val_mae: 0.3897 - val_mse: 0.2623 - val_keras_mape: 302.5383 - val_keras_wmape: 611.9034\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2747 - mae: 0.4060 - mse: 0.2747 - keras_mape: 257.4801 - keras_wmape: 648.1816 - val_loss: 0.2539 - val_mae: 0.3787 - val_mse: 0.2539 - val_keras_mape: 288.0654 - val_keras_wmape: 594.5157\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2665 - mae: 0.3977 - mse: 0.2665 - keras_mape: 278.0250 - keras_wmape: 634.9557 - val_loss: 0.2680 - val_mae: 0.3973 - val_mse: 0.2680 - val_keras_mape: 321.5195 - val_keras_wmape: 623.7111\n",
      "Epoch 8/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2665 - mae: 0.3964 - mse: 0.2665 - keras_mape: 274.3362 - keras_wmape: 632.9207 - val_loss: 0.2613 - val_mae: 0.3914 - val_mse: 0.2613 - val_keras_mape: 290.4815 - val_keras_wmape: 614.5655\n",
      "Epoch 9/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2573 - mae: 0.3898 - mse: 0.2573 - keras_mape: 278.2393 - keras_wmape: 622.2488 - val_loss: 0.2521 - val_mae: 0.3774 - val_mse: 0.2521 - val_keras_mape: 294.1409 - val_keras_wmape: 592.5140\n",
      "Epoch 10/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2582 - mae: 0.3899 - mse: 0.2582 - keras_mape: 294.7151 - keras_wmape: 622.5002 - val_loss: 0.2646 - val_mae: 0.3844 - val_mse: 0.2646 - val_keras_mape: 279.6329 - val_keras_wmape: 603.4326\n",
      "Epoch 11/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2509 - mae: 0.3851 - mse: 0.2509 - keras_mape: 272.7757 - keras_wmape: 614.8033 - val_loss: 0.2697 - val_mae: 0.3941 - val_mse: 0.2697 - val_keras_mape: 322.4189 - val_keras_wmape: 618.8143\n",
      "Epoch 12/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2502 - mae: 0.3825 - mse: 0.2502 - keras_mape: 270.0614 - keras_wmape: 610.6525 - val_loss: 0.2598 - val_mae: 0.3874 - val_mse: 0.2598 - val_keras_mape: 291.5152 - val_keras_wmape: 608.2694\n",
      "Epoch 13/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2448 - mae: 0.3792 - mse: 0.2448 - keras_mape: 287.3233 - keras_wmape: 605.3863 - val_loss: 0.2729 - val_mae: 0.3959 - val_mse: 0.2729 - val_keras_mape: 315.6458 - val_keras_wmape: 621.5724\n",
      "Epoch 14/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2417 - mae: 0.3761 - mse: 0.2417 - keras_mape: 276.0970 - keras_wmape: 600.4652 - val_loss: 0.2542 - val_mae: 0.3765 - val_mse: 0.2542 - val_keras_mape: 293.0011 - val_keras_wmape: 591.1797\n",
      "Epoch 15/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2399 - mae: 0.3735 - mse: 0.2399 - keras_mape: 290.8986 - keras_wmape: 596.2587 - val_loss: 0.2547 - val_mae: 0.3738 - val_mse: 0.2547 - val_keras_mape: 273.2415 - val_keras_wmape: 586.7933\n",
      "Epoch 16/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2371 - mae: 0.3735 - mse: 0.2371 - keras_mape: 282.1651 - keras_wmape: 596.2704 - val_loss: 0.2545 - val_mae: 0.3751 - val_mse: 0.2545 - val_keras_mape: 270.3523 - val_keras_wmape: 588.9797\n",
      "Epoch 17/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2363 - mae: 0.3725 - mse: 0.2363 - keras_mape: 302.1490 - keras_wmape: 594.6454 - val_loss: 0.2592 - val_mae: 0.3721 - val_mse: 0.2592 - val_keras_mape: 262.2899 - val_keras_wmape: 584.2501\n",
      "Epoch 18/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2323 - mae: 0.3684 - mse: 0.2323 - keras_mape: 274.5862 - keras_wmape: 588.1152 - val_loss: 0.2564 - val_mae: 0.3708 - val_mse: 0.2564 - val_keras_mape: 273.6722 - val_keras_wmape: 582.1570\n",
      "Epoch 19/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2348 - mae: 0.3707 - mse: 0.2348 - keras_mape: 273.5164 - keras_wmape: 591.8558 - val_loss: 0.2524 - val_mae: 0.3729 - val_mse: 0.2524 - val_keras_mape: 269.8327 - val_keras_wmape: 585.3820\n",
      "Epoch 20/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2299 - mae: 0.3645 - mse: 0.2299 - keras_mape: 304.7203 - keras_wmape: 581.8630 - val_loss: 0.2511 - val_mae: 0.3738 - val_mse: 0.2511 - val_keras_mape: 282.0058 - val_keras_wmape: 586.8480\n",
      "Epoch 21/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2245 - mae: 0.3622 - mse: 0.2245 - keras_mape: 293.7943 - keras_wmape: 578.1783 - val_loss: 0.2552 - val_mae: 0.3773 - val_mse: 0.2552 - val_keras_mape: 301.5863 - val_keras_wmape: 592.3832\n",
      "Epoch 22/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2228 - mae: 0.3595 - mse: 0.2228 - keras_mape: 299.8161 - keras_wmape: 573.9410 - val_loss: 0.2516 - val_mae: 0.3729 - val_mse: 0.2516 - val_keras_mape: 259.7251 - val_keras_wmape: 585.4568\n",
      "Epoch 23/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2200 - mae: 0.3552 - mse: 0.2200 - keras_mape: 269.0862 - keras_wmape: 567.0622 - val_loss: 0.2547 - val_mae: 0.3734 - val_mse: 0.2547 - val_keras_mape: 280.8852 - val_keras_wmape: 586.1981\n",
      "Epoch 24/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2192 - mae: 0.3573 - mse: 0.2192 - keras_mape: 287.6491 - keras_wmape: 570.3584 - val_loss: 0.2768 - val_mae: 0.3961 - val_mse: 0.2768 - val_keras_mape: 305.1400 - val_keras_wmape: 621.8723\n",
      "Epoch 25/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2142 - mae: 0.3524 - mse: 0.2142 - keras_mape: 276.8614 - keras_wmape: 562.6331 - val_loss: 0.2503 - val_mae: 0.3698 - val_mse: 0.2503 - val_keras_mape: 271.4776 - val_keras_wmape: 580.6583\n",
      "Epoch 26/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2113 - mae: 0.3485 - mse: 0.2113 - keras_mape: 256.7826 - keras_wmape: 556.4057 - val_loss: 0.2615 - val_mae: 0.3804 - val_mse: 0.2615 - val_keras_mape: 294.2934 - val_keras_wmape: 597.2007\n",
      "Epoch 27/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2125 - mae: 0.3495 - mse: 0.2125 - keras_mape: 277.5962 - keras_wmape: 558.0107 - val_loss: 0.2610 - val_mae: 0.3879 - val_mse: 0.2610 - val_keras_mape: 260.8665 - val_keras_wmape: 609.0594\n",
      "Epoch 00027: early stopping\n",
      "model fit time: 20.28205943107605\n",
      "split 10\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.5727 - mae: 0.5896 - mse: 0.5727 - keras_mape: 768.4541 - keras_wmape: 941.3424 - val_loss: 0.3276 - val_mae: 0.4586 - val_mse: 0.3276 - val_keras_mape: 173.9733 - val_keras_wmape: 719.9886\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3371 - mae: 0.4550 - mse: 0.3371 - keras_mape: 466.1663 - keras_wmape: 726.4557 - val_loss: 0.3044 - val_mae: 0.4407 - val_mse: 0.3044 - val_keras_mape: 192.2658 - val_keras_wmape: 691.9133\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.3136 - mae: 0.4367 - mse: 0.3136 - keras_mape: 475.1920 - keras_wmape: 697.1494 - val_loss: 0.3096 - val_mae: 0.4435 - val_mse: 0.3096 - val_keras_mape: 204.4333 - val_keras_wmape: 696.2635\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2950 - mae: 0.4216 - mse: 0.2950 - keras_mape: 436.8994 - keras_wmape: 673.1107 - val_loss: 0.2866 - val_mae: 0.4188 - val_mse: 0.2866 - val_keras_mape: 185.2742 - val_keras_wmape: 657.5157\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2880 - mae: 0.4160 - mse: 0.2880 - keras_mape: 471.3631 - keras_wmape: 664.2086 - val_loss: 0.2796 - val_mae: 0.4173 - val_mse: 0.2796 - val_keras_mape: 182.8057 - val_keras_wmape: 655.0896\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2770 - mae: 0.4057 - mse: 0.2770 - keras_mape: 411.3425 - keras_wmape: 647.7833 - val_loss: 0.2815 - val_mae: 0.4162 - val_mse: 0.2815 - val_keras_mape: 189.6103 - val_keras_wmape: 653.4231\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 5.609436511993408\n",
      "{'smape': 67.08008263347486, 'wmape': 43.7359610918194, 'mape': 187.70702276539015, 'mae': 32972996.9, 'rmse': 74499387.7, 'adj_r2': 0.6084431115533603}\n",
      "10 CV time: 88.08897662162781\n"
     ]
    }
   ],
   "source": [
    "cv_result = get_regression_cv_metrics(create_and_fit_nn_regressor_with_params, X, y,\n",
    "        n_splits=10, patience=5, model_params={}, verbose=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "smape: 67.08\nwmape: 43.736\nmape: 187.707\nmae: 32972996.9\nrmse: 74499387.7\nadj_r2: 0.608\n"
     ]
    }
   ],
   "source": [
    "print_output(cv_result['cv_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " mse: 0.2864 - val_loss: 0.2578 - val_mae: 0.3844 - val_mse: 0.2578\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2768 - mae: 0.4055 - mse: 0.2768 - val_loss: 0.2588 - val_mae: 0.3878 - val_mse: 0.2588\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2657 - mae: 0.3963 - mse: 0.2657 - val_loss: 0.2578 - val_mae: 0.3843 - val_mse: 0.2578\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2594 - mae: 0.3914 - mse: 0.2594 - val_loss: 0.2582 - val_mae: 0.3857 - val_mse: 0.2582\n",
      "Epoch 8/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2599 - mae: 0.3919 - mse: 0.2599 - val_loss: 0.2607 - val_mae: 0.3795 - val_mse: 0.2607\n",
      "Epoch 9/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2529 - mae: 0.3868 - mse: 0.2529 - val_loss: 0.2628 - val_mae: 0.3875 - val_mse: 0.2628\n",
      "Epoch 10/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2518 - mae: 0.3865 - mse: 0.2518 - val_loss: 0.2583 - val_mae: 0.3808 - val_mse: 0.2583\n",
      "Epoch 11/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2458 - mae: 0.3812 - mse: 0.2458 - val_loss: 0.2571 - val_mae: 0.3816 - val_mse: 0.2571\n",
      "Epoch 12/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2430 - mae: 0.3765 - mse: 0.2430 - val_loss: 0.2681 - val_mae: 0.3963 - val_mse: 0.2681\n",
      "Epoch 13/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2386 - mae: 0.3731 - mse: 0.2386 - val_loss: 0.2548 - val_mae: 0.3733 - val_mse: 0.2548\n",
      "Epoch 14/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2382 - mae: 0.3742 - mse: 0.2382 - val_loss: 0.2518 - val_mae: 0.3715 - val_mse: 0.2518\n",
      "Epoch 15/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2308 - mae: 0.3664 - mse: 0.2308 - val_loss: 0.2536 - val_mae: 0.3748 - val_mse: 0.2536\n",
      "Epoch 16/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2338 - mae: 0.3696 - mse: 0.2338 - val_loss: 0.2518 - val_mae: 0.3748 - val_mse: 0.2518\n",
      "Epoch 17/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2294 - mae: 0.3664 - mse: 0.2294 - val_loss: 0.2533 - val_mae: 0.3734 - val_mse: 0.2533\n",
      "Epoch 18/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2251 - mae: 0.3605 - mse: 0.2251 - val_loss: 0.2576 - val_mae: 0.3793 - val_mse: 0.2576\n",
      "Epoch 19/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2217 - mae: 0.3595 - mse: 0.2217 - val_loss: 0.2523 - val_mae: 0.3728 - val_mse: 0.2523\n",
      "Epoch 20/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2189 - mae: 0.3568 - mse: 0.2189 - val_loss: 0.2532 - val_mae: 0.3714 - val_mse: 0.2532\n",
      "Epoch 21/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2162 - mae: 0.3540 - mse: 0.2162 - val_loss: 0.2650 - val_mae: 0.3867 - val_mse: 0.2650\n",
      "Epoch 22/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2123 - mae: 0.3494 - mse: 0.2123 - val_loss: 0.2579 - val_mae: 0.3789 - val_mse: 0.2579\n",
      "Epoch 23/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2125 - mae: 0.3515 - mse: 0.2125 - val_loss: 0.2539 - val_mae: 0.3780 - val_mse: 0.2539\n",
      "Epoch 24/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2121 - mae: 0.3501 - mse: 0.2121 - val_loss: 0.2591 - val_mae: 0.3812 - val_mse: 0.2591\n",
      "Epoch 25/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2065 - mae: 0.3451 - mse: 0.2065 - val_loss: 0.2537 - val_mae: 0.3769 - val_mse: 0.2537\n",
      "Epoch 26/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1990 - mae: 0.3381 - mse: 0.1990 - val_loss: 0.2525 - val_mae: 0.3740 - val_mse: 0.2525\n",
      "Epoch 27/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1982 - mae: 0.3392 - mse: 0.1982 - val_loss: 0.2513 - val_mae: 0.3685 - val_mse: 0.2513\n",
      "Epoch 28/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1956 - mae: 0.3336 - mse: 0.1956 - val_loss: 0.2614 - val_mae: 0.3823 - val_mse: 0.2614\n",
      "Epoch 29/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1948 - mae: 0.3338 - mse: 0.1948 - val_loss: 0.2591 - val_mae: 0.3753 - val_mse: 0.2591\n",
      "Epoch 30/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1937 - mae: 0.3321 - mse: 0.1937 - val_loss: 0.2730 - val_mae: 0.3933 - val_mse: 0.2730\n",
      "Epoch 31/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1880 - mae: 0.3283 - mse: 0.1880 - val_loss: 0.2547 - val_mae: 0.3768 - val_mse: 0.2547\n",
      "Epoch 32/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1866 - mae: 0.3278 - mse: 0.1866 - val_loss: 0.2532 - val_mae: 0.3750 - val_mse: 0.2532\n",
      "Epoch 33/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1861 - mae: 0.3241 - mse: 0.1861 - val_loss: 0.2541 - val_mae: 0.3738 - val_mse: 0.2541\n",
      "Epoch 34/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1811 - mae: 0.3222 - mse: 0.1811 - val_loss: 0.2544 - val_mae: 0.3696 - val_mse: 0.2544\n",
      "Epoch 35/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1780 - mae: 0.3189 - mse: 0.1780 - val_loss: 0.2552 - val_mae: 0.3732 - val_mse: 0.2552\n",
      "Epoch 36/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1759 - mae: 0.3171 - mse: 0.1759 - val_loss: 0.2490 - val_mae: 0.3685 - val_mse: 0.2490\n",
      "Epoch 37/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1714 - mae: 0.3110 - mse: 0.1714 - val_loss: 0.2546 - val_mae: 0.3735 - val_mse: 0.2546\n",
      "Epoch 38/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1687 - mae: 0.3093 - mse: 0.1687 - val_loss: 0.2605 - val_mae: 0.3784 - val_mse: 0.2605\n",
      "Epoch 39/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1670 - mae: 0.3077 - mse: 0.1670 - val_loss: 0.2614 - val_mae: 0.3792 - val_mse: 0.2614\n",
      "Epoch 40/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1598 - mae: 0.3028 - mse: 0.1598 - val_loss: 0.2662 - val_mae: 0.3850 - val_mse: 0.2662\n",
      "Epoch 41/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1616 - mae: 0.3034 - mse: 0.1616 - val_loss: 0.2648 - val_mae: 0.3801 - val_mse: 0.2648\n",
      "Epoch 42/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1575 - mae: 0.3016 - mse: 0.1575 - val_loss: 0.2563 - val_mae: 0.3731 - val_mse: 0.2563\n",
      "Epoch 43/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1541 - mae: 0.2946 - mse: 0.1541 - val_loss: 0.2683 - val_mae: 0.3852 - val_mse: 0.2683\n",
      "Epoch 44/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1531 - mae: 0.2955 - mse: 0.1531 - val_loss: 0.2690 - val_mae: 0.3833 - val_mse: 0.2690\n",
      "Epoch 45/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1495 - mae: 0.2914 - mse: 0.1495 - val_loss: 0.2600 - val_mae: 0.3750 - val_mse: 0.2600\n",
      "Epoch 46/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1480 - mae: 0.2895 - mse: 0.1480 - val_loss: 0.2774 - val_mae: 0.3902 - val_mse: 0.2774\n",
      "Epoch 47/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1445 - mae: 0.2846 - mse: 0.1445 - val_loss: 0.2735 - val_mae: 0.3876 - val_mse: 0.2735\n",
      "Epoch 48/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1435 - mae: 0.2850 - mse: 0.1435 - val_loss: 0.2767 - val_mae: 0.3878 - val_mse: 0.2767\n",
      "Epoch 49/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1409 - mae: 0.2833 - mse: 0.1409 - val_loss: 0.2609 - val_mae: 0.3747 - val_mse: 0.2609\n",
      "Epoch 50/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1372 - mae: 0.2799 - mse: 0.1372 - val_loss: 0.2738 - val_mae: 0.3797 - val_mse: 0.2738\n",
      "Epoch 51/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1330 - mae: 0.2738 - mse: 0.1330 - val_loss: 0.2839 - val_mae: 0.3899 - val_mse: 0.2839\n",
      "Epoch 52/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1333 - mae: 0.2754 - mse: 0.1333 - val_loss: 0.2729 - val_mae: 0.3774 - val_mse: 0.2729\n",
      "Epoch 53/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1311 - mae: 0.2743 - mse: 0.1311 - val_loss: 0.2824 - val_mae: 0.3804 - val_mse: 0.2824\n",
      "Epoch 54/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1273 - mae: 0.2688 - mse: 0.1273 - val_loss: 0.3030 - val_mae: 0.3990 - val_mse: 0.3030\n",
      "Epoch 55/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1278 - mae: 0.2686 - mse: 0.1278 - val_loss: 0.2881 - val_mae: 0.3880 - val_mse: 0.2881\n",
      "Epoch 56/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1234 - mae: 0.2658 - mse: 0.1234 - val_loss: 0.2871 - val_mae: 0.3839 - val_mse: 0.2871\n",
      "Epoch 57/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1196 - mae: 0.2622 - mse: 0.1196 - val_loss: 0.2873 - val_mae: 0.3806 - val_mse: 0.2873\n",
      "Epoch 58/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1207 - mae: 0.2616 - mse: 0.1207 - val_loss: 0.2814 - val_mae: 0.3794 - val_mse: 0.2814\n",
      "Epoch 59/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1163 - mae: 0.2577 - mse: 0.1163 - val_loss: 0.2896 - val_mae: 0.3879 - val_mse: 0.2896\n",
      "Epoch 60/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1167 - mae: 0.2594 - mse: 0.1167 - val_loss: 0.3006 - val_mae: 0.3910 - val_mse: 0.3006\n",
      "Epoch 61/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1119 - mae: 0.2533 - mse: 0.1119 - val_loss: 0.2903 - val_mae: 0.3833 - val_mse: 0.2903\n",
      "Epoch 62/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1113 - mae: 0.2528 - mse: 0.1113 - val_loss: 0.2868 - val_mae: 0.3788 - val_mse: 0.2868\n",
      "Epoch 63/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1132 - mae: 0.2535 - mse: 0.1132 - val_loss: 0.2887 - val_mae: 0.3847 - val_mse: 0.2887\n",
      "Epoch 64/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1128 - mae: 0.2553 - mse: 0.1128 - val_loss: 0.3043 - val_mae: 0.3910 - val_mse: 0.3043\n",
      "Epoch 65/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1084 - mae: 0.2498 - mse: 0.1084 - val_loss: 0.3151 - val_mae: 0.4001 - val_mse: 0.3151\n",
      "Epoch 66/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1051 - mae: 0.2460 - mse: 0.1051 - val_loss: 0.2890 - val_mae: 0.3786 - val_mse: 0.2890\n",
      "Epoch 00066: early stopping\n",
      "model fit time: 36.72177243232727\n",
      "split 10\n",
      "Epoch 1/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.5873 - mae: 0.5931 - mse: 0.5873 - val_loss: 0.3487 - val_mae: 0.4561 - val_mse: 0.3487\n",
      "Epoch 2/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.3381 - mae: 0.4570 - mse: 0.3381 - val_loss: 0.2983 - val_mae: 0.4287 - val_mse: 0.2983\n",
      "Epoch 3/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.3001 - mae: 0.4252 - mse: 0.3001 - val_loss: 0.2889 - val_mae: 0.4193 - val_mse: 0.2889\n",
      "Epoch 4/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2889 - mae: 0.4176 - mse: 0.2889 - val_loss: 0.2827 - val_mae: 0.4178 - val_mse: 0.2827\n",
      "Epoch 5/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2768 - mae: 0.4064 - mse: 0.2768 - val_loss: 0.2807 - val_mae: 0.4192 - val_mse: 0.2807\n",
      "Epoch 6/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2717 - mae: 0.4035 - mse: 0.2717 - val_loss: 0.2721 - val_mae: 0.4110 - val_mse: 0.2721\n",
      "Epoch 7/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2647 - mae: 0.3983 - mse: 0.2647 - val_loss: 0.2725 - val_mae: 0.4097 - val_mse: 0.2725\n",
      "Epoch 8/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2586 - mae: 0.3915 - mse: 0.2586 - val_loss: 0.2723 - val_mae: 0.4113 - val_mse: 0.2723\n",
      "Epoch 9/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2567 - mae: 0.3903 - mse: 0.2567 - val_loss: 0.2703 - val_mae: 0.4086 - val_mse: 0.2703\n",
      "Epoch 10/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2517 - mae: 0.3864 - mse: 0.2517 - val_loss: 0.2772 - val_mae: 0.4168 - val_mse: 0.2772\n",
      "Epoch 11/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2477 - mae: 0.3833 - mse: 0.2477 - val_loss: 0.2776 - val_mae: 0.4184 - val_mse: 0.2776\n",
      "Epoch 12/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2482 - mae: 0.3812 - mse: 0.2482 - val_loss: 0.2681 - val_mae: 0.4045 - val_mse: 0.2681\n",
      "Epoch 13/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2409 - mae: 0.3771 - mse: 0.2409 - val_loss: 0.2735 - val_mae: 0.4195 - val_mse: 0.2735\n",
      "Epoch 14/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2410 - mae: 0.3762 - mse: 0.2410 - val_loss: 0.2677 - val_mae: 0.4085 - val_mse: 0.2677\n",
      "Epoch 15/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2369 - mae: 0.3727 - mse: 0.2369 - val_loss: 0.2696 - val_mae: 0.4117 - val_mse: 0.2696\n",
      "Epoch 16/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2313 - mae: 0.3690 - mse: 0.2313 - val_loss: 0.2635 - val_mae: 0.4064 - val_mse: 0.2635\n",
      "Epoch 17/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2318 - mae: 0.3687 - mse: 0.2318 - val_loss: 0.2581 - val_mae: 0.3978 - val_mse: 0.2581\n",
      "Epoch 18/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2295 - mae: 0.3674 - mse: 0.2295 - val_loss: 0.2646 - val_mae: 0.4074 - val_mse: 0.2646\n",
      "Epoch 19/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2238 - mae: 0.3615 - mse: 0.2238 - val_loss: 0.2653 - val_mae: 0.4085 - val_mse: 0.2653\n",
      "Epoch 20/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2230 - mae: 0.3607 - mse: 0.2230 - val_loss: 0.2623 - val_mae: 0.4048 - val_mse: 0.2623\n",
      "Epoch 21/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2183 - mae: 0.3563 - mse: 0.2183 - val_loss: 0.2612 - val_mae: 0.3990 - val_mse: 0.2612\n",
      "Epoch 22/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2160 - mae: 0.3543 - mse: 0.2160 - val_loss: 0.2644 - val_mae: 0.4094 - val_mse: 0.2644\n",
      "Epoch 23/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2110 - mae: 0.3516 - mse: 0.2110 - val_loss: 0.2563 - val_mae: 0.3971 - val_mse: 0.2563\n",
      "Epoch 24/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.2081 - mae: 0.3483 - mse: 0.2081 - val_loss: 0.2547 - val_mae: 0.3983 - val_mse: 0.2547\n",
      "Epoch 25/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2043 - mae: 0.3442 - mse: 0.2043 - val_loss: 0.2496 - val_mae: 0.3909 - val_mse: 0.2496\n",
      "Epoch 26/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.2051 - mae: 0.3444 - mse: 0.2051 - val_loss: 0.2559 - val_mae: 0.4006 - val_mse: 0.2559\n",
      "Epoch 27/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.2017 - mae: 0.3435 - mse: 0.2017 - val_loss: 0.2599 - val_mae: 0.4050 - val_mse: 0.2599\n",
      "Epoch 28/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1984 - mae: 0.3386 - mse: 0.1984 - val_loss: 0.2523 - val_mae: 0.3969 - val_mse: 0.2523\n",
      "Epoch 29/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1959 - mae: 0.3380 - mse: 0.1959 - val_loss: 0.2583 - val_mae: 0.4014 - val_mse: 0.2583\n",
      "Epoch 30/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1901 - mae: 0.3310 - mse: 0.1901 - val_loss: 0.2552 - val_mae: 0.3981 - val_mse: 0.2552\n",
      "Epoch 31/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1913 - mae: 0.3332 - mse: 0.1913 - val_loss: 0.2559 - val_mae: 0.3957 - val_mse: 0.2559\n",
      "Epoch 32/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1892 - mae: 0.3300 - mse: 0.1892 - val_loss: 0.2608 - val_mae: 0.4024 - val_mse: 0.2608\n",
      "Epoch 33/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1817 - mae: 0.3237 - mse: 0.1817 - val_loss: 0.2546 - val_mae: 0.3948 - val_mse: 0.2546\n",
      "Epoch 34/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1835 - mae: 0.3268 - mse: 0.1835 - val_loss: 0.2534 - val_mae: 0.3971 - val_mse: 0.2534\n",
      "Epoch 35/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1770 - mae: 0.3202 - mse: 0.1770 - val_loss: 0.2499 - val_mae: 0.3955 - val_mse: 0.2499\n",
      "Epoch 36/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1758 - mae: 0.3177 - mse: 0.1758 - val_loss: 0.2570 - val_mae: 0.3999 - val_mse: 0.2570\n",
      "Epoch 37/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1713 - mae: 0.3143 - mse: 0.1713 - val_loss: 0.2516 - val_mae: 0.3944 - val_mse: 0.2516\n",
      "Epoch 38/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1683 - mae: 0.3105 - mse: 0.1683 - val_loss: 0.2511 - val_mae: 0.3949 - val_mse: 0.2511\n",
      "Epoch 39/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1700 - mae: 0.3125 - mse: 0.1700 - val_loss: 0.2579 - val_mae: 0.4018 - val_mse: 0.2579\n",
      "Epoch 40/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1649 - mae: 0.3070 - mse: 0.1649 - val_loss: 0.2565 - val_mae: 0.3968 - val_mse: 0.2565\n",
      "Epoch 41/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1587 - mae: 0.3025 - mse: 0.1587 - val_loss: 0.2529 - val_mae: 0.3961 - val_mse: 0.2529\n",
      "Epoch 42/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1568 - mae: 0.2994 - mse: 0.1568 - val_loss: 0.2533 - val_mae: 0.3961 - val_mse: 0.2533\n",
      "Epoch 43/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1540 - mae: 0.2996 - mse: 0.1540 - val_loss: 0.2565 - val_mae: 0.4021 - val_mse: 0.2565\n",
      "Epoch 44/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1503 - mae: 0.2927 - mse: 0.1503 - val_loss: 0.2527 - val_mae: 0.3959 - val_mse: 0.2527\n",
      "Epoch 45/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1503 - mae: 0.2931 - mse: 0.1503 - val_loss: 0.2572 - val_mae: 0.3962 - val_mse: 0.2572\n",
      "Epoch 46/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1481 - mae: 0.2919 - mse: 0.1481 - val_loss: 0.2513 - val_mae: 0.3899 - val_mse: 0.2513\n",
      "Epoch 47/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1418 - mae: 0.2847 - mse: 0.1418 - val_loss: 0.2525 - val_mae: 0.3943 - val_mse: 0.2525\n",
      "Epoch 48/10000\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.1430 - mae: 0.2881 - mse: 0.1430 - val_loss: 0.2562 - val_mae: 0.4014 - val_mse: 0.2562\n",
      "Epoch 49/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1407 - mae: 0.2832 - mse: 0.1407 - val_loss: 0.2582 - val_mae: 0.3994 - val_mse: 0.2582\n",
      "Epoch 50/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1361 - mae: 0.2798 - mse: 0.1361 - val_loss: 0.2515 - val_mae: 0.3902 - val_mse: 0.2515\n",
      "Epoch 51/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1335 - mae: 0.2749 - mse: 0.1335 - val_loss: 0.2618 - val_mae: 0.4051 - val_mse: 0.2618\n",
      "Epoch 52/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1301 - mae: 0.2719 - mse: 0.1301 - val_loss: 0.2574 - val_mae: 0.3986 - val_mse: 0.2574\n",
      "Epoch 53/10000\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 0.1273 - mae: 0.2713 - mse: 0.1273 - val_loss: 0.2517 - val_mae: 0.3930 - val_mse: 0.2517\n",
      "Epoch 54/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1255 - mae: 0.2682 - mse: 0.1255 - val_loss: 0.2576 - val_mae: 0.3991 - val_mse: 0.2576\n",
      "Epoch 55/10000\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 0.1261 - mae: 0.2678 - mse: 0.1261 - val_loss: 0.2586 - val_mae: 0.3979 - val_mse: 0.2586\n",
      "Epoch 00055: early stopping\n",
      "model fit time: 30.776304960250854\n",
      "{'smape': 63.92951759246724, 'mape': 187.99516415775733, 'mae': 31762673.1, 'rmse': 73387374.9, 'adj_r2': 0.5937256713328222}\n",
      "10 CV time: 383.5597198009491\n"
     ]
    }
   ],
   "source": [
    "cv_result = get_regression_cv_metrics(create_and_fit_nn_regressor_with_params, X, y,\n",
    "        n_splits=10, patience=30, model_params={}, verbose=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "smape: 63.93\nmape: 187.995\nmae: 31762673.1\nrmse: 73387374.9\nadj_r2: 0.594\n"
     ]
    }
   ],
   "source": [
    "print_output(cv_result['cv_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nn_params(params):\n",
    "    return {}\n",
    "    # get_float = lambda val: max(min(val, 1), 0)\n",
    "    # get_int = lambda val: int(round(val))\n",
    "    # activations = ['relu', 'elu', 'selu', 'sigmoid', 'tanh']\n",
    "    # get_activation = lambda i: activations[max(min(get_int(i), 4), 0)]\n",
    "\n",
    "    # return_params = {\n",
    "    #     'adamax_learning_rate': params['adamax_learning_rate'],\n",
    "    #     # 'adamax_beta_1': get_float(params['adamax_beta_1']),\n",
    "    #     # 'adamax_beta_2': get_float(params['adamax_beta_2']),\n",
    "    #     # 'batch_size': get_int(params['batch_size']),\n",
    "    #     # 'hidden_layers': max(min(get_int(params['hidden_layers'], 4), 0),\n",
    "    # }\n",
    "    # for l in range(1, 3):\n",
    "    #     return_params[f'l{l}_neurons'] = get_int(params[f'l{l}_neurons'])\n",
    "    #     return_params[f'l{l}_activation'] = get_activation(params[f'l{l}_activation'])\n",
    "    #     # return_params[f'l{l}_kernel_regularizer_l1'] = get_float(params[f'l{l}_kernel_regularizer_l1'])\n",
    "    #     # return_params[f'l{l}_kernel_regularizer_l2'] = get_float(params[f'l{l}_kernel_regularizer_l2'])\n",
    "    #     return_params[f'l{l}_dropout'] = get_float(params[f'l{l}_dropout'])\n",
    "\n",
    "    # return return_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune lgb binary classifier with hyperas\n",
    "from hyperopt import Trials, STATUS_OK, tpe, rand\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def get_data():\n",
    "    with open(f'outliers/final/nan_filled_data.pickle', 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data['X_train'], data['y_train'], data['X_val'], data['y_val'], data['X_test'], data['y_test']\n",
    "    X = pd.concat([X_train, X_test, X_val])\n",
    "    y = np.concatenate([y_train, y_test, y_val])\n",
    "    return X, y\n",
    "\n",
    "def get_nn_hyperas_model(X, y):\n",
    "    # adamax_learning_rate={{uniform(0.0001, 0.001)}}\n",
    "    # # adamax_beta_1={{uniform(0.8, 1)}}\n",
    "    # # adamax_beta_2={{uniform(0.95, 1)}}\n",
    "    # # batch_size={{uniform(4, 1024)}}\n",
    "    # l1_neurons={{uniform(64, 1024)}}\n",
    "    # l1_activation={{uniform(0, 4)}}\n",
    "    # # l1_kernel_regularizer_l1={{uniform(0, 0.05)}}\n",
    "    # # l1_kernel_regularizer_l2={{uniform(0, 0.05)}}\n",
    "    # l1_dropout={{uniform(0, 0.8)}}\n",
    "    # l2_neurons={{uniform(64, 1024)}}\n",
    "    # l2_activation={{uniform(0, 4)}}\n",
    "    # # l2_kernel_regularizer_l1={{uniform(0, 0.05)}}\n",
    "    # # l2_kernel_regularizer_l2={{uniform(0, 0.05)}}\n",
    "    # l2_dropout={{uniform(0, 0.8)}}\n",
    "   \n",
    "    params_raw = {}\n",
    "    #     'adamax_learning_rate': adamax_learning_rate,\n",
    "    #     # 'adamax_beta_1': adamax_beta_1,\n",
    "    #     # 'adamax_beta_2': adamax_beta_2,\n",
    "    #     'l1_neurons': l1_neurons,\n",
    "    #     'l1_activation': l1_activation,\n",
    "    #     # 'l1_kernel_regularizer_l1': l1_kernel_regularizer_l1,\n",
    "    #     # 'l1_kernel_regularizer_l2': l1_kernel_regularizer_l2,\n",
    "    #     'l1_dropout': l1_dropout,\n",
    "    #     'l2_neurons': l2_neurons,\n",
    "    #     'l2_activation': l2_activation,\n",
    "    #     # 'l2_kernel_regularizer_l1': l2_kernel_regularizer_l1,\n",
    "    #     # 'l2_kernel_regularizer_l2': l2_kernel_regularizer_l2,\n",
    "    #     'l2_dropout': l2_dropout,\n",
    "    # }\n",
    "    params = convert_nn_params(params_raw)\n",
    "    print(params)\n",
    "    cv_result = get_regression_cv_metrics(create_and_fit_nn_regressor_with_params, X, y,\n",
    "        n_splits=10, patience=5, validation_size=0.05, regressor_params=params, verbose=1)\n",
    "    return {'loss': cv_result['cv_metrics']['smape'], 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", patience=30, regressor_params=None, verbose=0):\n",
      "  51:     start = time.time()\n",
      "  52:     print(f'x shape {X.shape[0]}')\n",
      "  53:     fit_params = {\n",
      "  54:         'model__epochs': 10000,\n",
      "  55:         'model__shuffle': True,\n",
      "  56:         'model__use_multiprocessing': True,\n",
      "  57:         'model__verbose': verbose,\n",
      "  58:         'model__validation_data': (X_val, y_val),\n",
      "  59:         # 'model__batch_size': regressor_params.pop('batch_size'),\n",
      "  60:         # 'model__batch_size': 32,\n",
      "  61:         'model__batch_size': X.shape[0],\n",
      "  62:         'model__callbacks': [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)],\n",
      "  63:     }\n",
      "  64:     model = TransformedTargetRegressor(\n",
      "  65:         Pipeline([\n",
      "  66:             ('powertransform', PowerTransformer()),\n",
      "  67:             ('model', KerasRegressor(build_nn_model_with_params([X.shape[1]], regressor_params))),\n",
      "  68:         ]),\n",
      "  69:         PowerTransformer(),\n",
      "  70:     ).fit(X, y, **fit_params)\n",
      "  71:     end = time.time()\n",
      "  72:     print(f'model fit time: {end - start}')\n",
      "  73:     return model\n",
      "  74: \n",
      "  75: def build_nn_model_with_params(input_shape, params):\n",
      "  76:     def get_model():\n",
      "  77:         adamax = Adamax(learning_rate=0.001,beta_1=0.958,beta_2=0.987)\n",
      "  78:         model = Sequential([\n",
      "  79:             Dense(\n",
      "  80:                 256, \n",
      "  81:                 activation='sigmoid', \n",
      "  82:                 input_shape=input_shape,\n",
      "  83:                 kernel_initializer='glorot_normal',\n",
      "  84:                 kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001),\n",
      "  85:                 bias_regularizer=l1_l2(l1=0.001, l2=0.1)\n",
      "  86:             ),\n",
      "  87:             Dropout(0.005),\n",
      "  88:             Dense(\n",
      "  89:                 256, \n",
      "  90:                 activation='sigmoid',\n",
      "  91:                 kernel_initializer='glorot_normal',\n",
      "  92:                 kernel_regularizer=l1_l2(l1=0, l2=0.001),\n",
      "  93:                 bias_regularizer=l1_l2(l1=0.01, l2=0.01),\n",
      "  94:             ),\n",
      "  95:             Dropout(0.5),\n",
      "  96:             Dense(1, kernel_initializer='glorot_normal')\n",
      "  97:         ])\n",
      "  98: \n",
      "  99:         model.compile(loss=losses.MeanSquaredError(),\n",
      " 100:                     optimizer=adamax,\n",
      " 101:                     metrics=['mae', 'mse'])\n",
      " 102:         return model\n",
      " 103:     return get_model\n",
      " 104: \n",
      " 105: \n",
      ">>> Data\n",
      "  1: \n",
      "  2: with open(f'outliers/final/nan_filled_data.pickle', 'rb') as handle:\n",
      "  3:     data = pickle.load(handle)\n",
      "  4: \n",
      "  5: X_train, y_train, X_val, y_val, X_test, y_test = data['X_train'], data['y_train'], data['X_val'], data['y_val'], data['X_test'], data['y_test']\n",
      "  6: X = pd.concat([X_train, X_test, X_val])\n",
      "  7: y = np.concatenate([y_train, y_test, y_val])\n",
      "  8: \n",
      "  9: \n",
      " 10: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     adamax_learning_rate=space['adamax_learning_rate']\n",
      "   4:     # adamax_beta_1=space['adamax_beta_1']\n",
      "   5:     # adamax_beta_2=space['adamax_beta_2']\n",
      "   6:     # batch_size=space['batch_size']\n",
      "   7:     l1_neurons=space['l1_neurons']\n",
      "   8:     l1_activation=space['l1_activation']\n",
      "   9:     # l1_kernel_regularizer_l1=space['l1_kernel_regularizer_l1']\n",
      "  10:     # l1_kernel_regularizer_l2=space['l1_kernel_regularizer_l1_1']\n",
      "  11:     l1_dropout=space['l1_dropout']\n",
      "  12:     l2_neurons=space['l1_neurons_1']\n",
      "  13:     l2_activation=space['l1_activation_1']\n",
      "  14:     # l2_kernel_regularizer_l1=space['l1_kernel_regularizer_l1_2']\n",
      "  15:     # l2_kernel_regularizer_l2=space['l1_kernel_regularizer_l1_3']\n",
      "  16:     l2_dropout=space['l1_dropout_1']\n",
      "  17:    \n",
      "  18:     params_raw = {\n",
      "  19:         'adamax_learning_rate': adamax_learning_rate,\n",
      "  20:         # 'adamax_beta_1': adamax_beta_1,\n",
      "  21:         # 'adamax_beta_2': adamax_beta_2,\n",
      "  22:         'l1_neurons': l1_neurons,\n",
      "  23:         'l1_activation': l1_activation,\n",
      "  24:         # 'l1_kernel_regularizer_l1': l1_kernel_regularizer_l1,\n",
      "  25:         # 'l1_kernel_regularizer_l2': l1_kernel_regularizer_l2,\n",
      "  26:         'l1_dropout': l1_dropout,\n",
      "  27:         'l2_neurons': l2_neurons,\n",
      "  28:         'l2_activation': l2_activation,\n",
      "  29:         # 'l2_kernel_regularizer_l1': l2_kernel_regularizer_l1,\n",
      "  30:         # 'l2_kernel_regularizer_l2': l2_kernel_regularizer_l2,\n",
      "  31:         'l2_dropout': l2_dropout,\n",
      "  32:     }\n",
      "  33:     params = convert_nn_params(params_raw)\n",
      "  34:     print(params)\n",
      "  35:     cv_result = get_regression_cv_metrics(create_and_fit_nn_regressor_with_params, X, y,\n",
      "  36:         n_splits=10, patience=5, validation_size=0.05, regressor_params=params, verbose=1)\n",
      "  37:     return {'loss': cv_result['cv_metrics']['smape'], 'status': STATUS_OK}\n",
      "  38: \n",
      "{'adamax_learning_rate': 0.0002485101665575702, 'l1_neurons': 690, 'l1_activation': 'relu', 'l1_dropout': 0.6582744887138203, 'l2_neurons': 484, 'l2_activation': 'elu', 'l2_dropout': 0.05229584243240595}\n",
      "split 1\n",
      "x shape 5954\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 3.0553 - mae: 1.2728 - mse: 2.4667\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 166ms/step - loss: 3.0553 - mae: 1.2728 - mse: 2.4667 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1406 - mae: 0.9987 - mse: 1.5498\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 23ms/step - loss: 2.1406 - mae: 0.9987 - mse: 1.5498 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0043 - mae: 0.9606 - mse: 1.4132\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 25ms/step - loss: 2.0043 - mae: 0.9606 - mse: 1.4132 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0405 - mae: 0.9729 - mse: 1.4499\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 23ms/step - loss: 2.0405 - mae: 0.9729 - mse: 1.4499 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0679 - mae: 0.9861 - mse: 1.4782\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 25ms/step - loss: 2.0679 - mae: 0.9861 - mse: 1.4782 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0104 - mae: 0.9661 - mse: 1.4219\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 22ms/step - loss: 2.0104 - mae: 0.9661 - mse: 1.4219 - val_loss: 55358198550364160.0000 - val_mae: 91821848.0000 - val_mse: 55358198550364160.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.8348543643951416\n",
      "split 2\n",
      "x shape 5954\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1701 - mae: 1.0200 - mse: 1.5812\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 182ms/step - loss: 2.1701 - mae: 1.0200 - mse: 1.5812 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0529 - mae: 0.9727 - mse: 1.4626\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 2.0529 - mae: 0.9727 - mse: 1.4626 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8799 - mae: 0.9124 - mse: 1.2913\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 1.8799 - mae: 0.9124 - mse: 1.2913 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8430 - mae: 0.8977 - mse: 1.2564\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 1.8430 - mae: 0.8977 - mse: 1.2564 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.7281 - mae: 0.8531 - mse: 1.1421\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.7281 - mae: 0.8531 - mse: 1.1421 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.6320 - mae: 0.8093 - mse: 1.0469\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 22ms/step - loss: 1.6320 - mae: 0.8093 - mse: 1.0469 - val_loss: 18317462139305984.0000 - val_mae: 69253784.0000 - val_mse: 18317462139305984.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.28131103515625\n",
      "split 3\n",
      "x shape 5954\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.8108 - mae: 1.2034 - mse: 2.2211\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 155ms/step - loss: 2.8108 - mae: 1.2034 - mse: 2.2211 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1005 - mae: 0.9904 - mse: 1.5087\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 2.1005 - mae: 0.9904 - mse: 1.5087 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0699 - mae: 0.9816 - mse: 1.4779\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 2.0699 - mae: 0.9816 - mse: 1.4779 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1286 - mae: 1.0013 - mse: 1.5375\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 23ms/step - loss: 2.1286 - mae: 1.0013 - mse: 1.5375 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0975 - mae: 1.0022 - mse: 1.5076\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 24ms/step - loss: 2.0975 - mae: 1.0022 - mse: 1.5076 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9251 - mae: 0.9357 - mse: 1.3365\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.9251 - mae: 0.9357 - mse: 1.3365 - val_loss: 22656152202379264.0000 - val_mae: 68933840.0000 - val_mse: 22656152202379264.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.1869585514068604\n",
      "split 4\n",
      "x shape 5954\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.9030 - mae: 1.2342 - mse: 2.3146\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 152ms/step - loss: 2.9030 - mae: 1.2342 - mse: 2.3146 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1311 - mae: 0.9921 - mse: 1.5404\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 24ms/step - loss: 2.1311 - mae: 0.9921 - mse: 1.5404 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0969 - mae: 0.9829 - mse: 1.5061\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 2.0969 - mae: 0.9829 - mse: 1.5061 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1102 - mae: 0.9821 - mse: 1.5203\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 2.1102 - mae: 0.9821 - mse: 1.5203 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0828 - mae: 0.9733 - mse: 1.4941\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 2.0828 - mae: 0.9733 - mse: 1.4941 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9353 - mae: 0.9258 - mse: 1.3478\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 1.9353 - mae: 0.9258 - mse: 1.3478 - val_loss: 28544036969119744.0000 - val_mae: 86955928.0000 - val_mse: 28544036969119744.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.186875581741333\n",
      "split 5\n",
      "x shape 5954\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.4701 - mae: 1.0986 - mse: 1.8825\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 147ms/step - loss: 2.4701 - mae: 1.0986 - mse: 1.8825 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1325 - mae: 1.0019 - mse: 1.5426\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 2.1325 - mae: 1.0019 - mse: 1.5426 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1642 - mae: 1.0176 - mse: 1.5749\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 2.1642 - mae: 1.0176 - mse: 1.5749 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0738 - mae: 0.9848 - mse: 1.4860\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 24ms/step - loss: 2.0738 - mae: 0.9848 - mse: 1.4860 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9391 - mae: 0.9374 - mse: 1.3529\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.9391 - mae: 0.9374 - mse: 1.3529 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8003 - mae: 0.8823 - mse: 1.2146\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.8003 - mae: 0.8823 - mse: 1.2146 - val_loss: 24431144074215424.0000 - val_mae: 81480512.0000 - val_mse: 24431144074215424.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.1563544273376465\n",
      "split 6\n",
      "x shape 5955\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.2078 - mae: 1.0236 - mse: 1.6199\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 157ms/step - loss: 2.2078 - mae: 1.0236 - mse: 1.6199 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1904 - mae: 1.0134 - mse: 1.6006\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 18ms/step - loss: 2.1904 - mae: 1.0134 - mse: 1.6006 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0989 - mae: 0.9878 - mse: 1.5109\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 2.0989 - mae: 0.9878 - mse: 1.5109 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9019 - mae: 0.9167 - mse: 1.3161\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.9019 - mae: 0.9167 - mse: 1.3161 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8139 - mae: 0.8882 - mse: 1.2284\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 1.8139 - mae: 0.8882 - mse: 1.2284 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8652 - mae: 0.9113 - mse: 1.2799\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.8652 - mae: 0.9113 - mse: 1.2799 - val_loss: 20373995559845888.0000 - val_mae: 69742000.0000 - val_mse: 20373995559845888.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.2215871810913086\n",
      "split 7\n",
      "x shape 5955\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0185 - mae: 0.9672 - mse: 1.4288\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 173ms/step - loss: 2.0185 - mae: 0.9672 - mse: 1.4288 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9349 - mae: 0.9314 - mse: 1.3440\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.9349 - mae: 0.9314 - mse: 1.3440 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.7774 - mae: 0.8774 - mse: 1.1884\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 20ms/step - loss: 1.7774 - mae: 0.8774 - mse: 1.1884 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.7219 - mae: 0.8549 - mse: 1.1350\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 24ms/step - loss: 1.7219 - mae: 0.8549 - mse: 1.1350 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.5975 - mae: 0.8027 - mse: 1.0113\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 23ms/step - loss: 1.5975 - mae: 0.8027 - mse: 1.0113 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.5626 - mae: 0.7871 - mse: 0.9775\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 24ms/step - loss: 1.5626 - mae: 0.7871 - mse: 0.9775 - val_loss: 26458364342960128.0000 - val_mae: 74445544.0000 - val_mse: 26458364342960128.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.2536885738372803\n",
      "split 8\n",
      "x shape 5955\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.4986 - mae: 1.1118 - mse: 1.9114\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 159ms/step - loss: 2.4986 - mae: 1.1118 - mse: 1.9114 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 2/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.0599 - mae: 0.9750 - mse: 1.4705\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 19ms/step - loss: 2.0599 - mae: 0.9750 - mse: 1.4705 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 3/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.1117 - mae: 0.9885 - mse: 1.5231\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 22ms/step - loss: 2.1117 - mae: 0.9885 - mse: 1.5231 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 4/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.9762 - mae: 0.9348 - mse: 1.3892\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 21ms/step - loss: 1.9762 - mae: 0.9348 - mse: 1.3892 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 5/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.8840 - mae: 0.9129 - mse: 1.2984\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 23ms/step - loss: 1.8840 - mae: 0.9129 - mse: 1.2984 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 6/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 1.7623 - mae: 0.8662 - mse: 1.1774\n",
      "\b\n",
      "1/1 [==============================]\n",
      " - 0s 22ms/step - loss: 1.7623 - mae: 0.8662 - mse: 1.1774 - val_loss: 32509054140022784.0000 - val_mae: 78389384.0000 - val_mse: 32509054140022784.0000\n",
      "\n",
      "Epoch 00006: early stopping\n",
      "model fit time: 2.2904467582702637\n",
      "split 9\n",
      "x shape 5955\n",
      "Epoch 1/10000\n",
      "1/1 [==============================]\n",
      " - ETA: 0s - loss: 2.2077 - mae: 1.0239 - mse: 1.6160\n",
      "  0%|          | 0/30 [00:23<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-547bc7a1eb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m best_run, best_model, space = optim.minimize(model=get_nn_hyperas_model,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                       \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     best_run, space = base_minimizer(model=model,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                      \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                      \u001b[0mfunctions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     return (\n\u001b[0;32m--> 133\u001b[0;31m         fmin(keras_fmin_fnct,\n\u001b[0m\u001b[1;32m    134\u001b[0m              \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m              \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/thesis/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;32m~/thesis/temp_model.py\u001b[0m in \u001b[0;36mget_regression_cv_metrics\u001b[0;34m(create_and_fit_fn, X, y, n_splits, patience, validation_size, regressor_params, should_output_metrics, should_output_graphs, verbose)\u001b[0m\n",
      "\u001b[0;32m~/thesis/temp_model.py\u001b[0m in \u001b[0;36mcreate_and_fit_nn_regressor_with_params\u001b[0;34m(X, y, X_val, y_val, patience, regressor_params, verbose)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/compose/_target.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1217\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2945\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    821\u001b[0m     \"\"\"\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(\n\u001b[0m\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m           name=name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m     57\u001b[0m         \"AssignAddVariableOp\", resource=resource, value=value, name=name)\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m           values = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    466\u001b[0m               \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1466\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1467\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_captures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m       placeholder = _create_substitute_placeholder(\n\u001b[0m\u001b[1;32m    648\u001b[0m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[1;32m    649\u001b[0m       \u001b[0;31m# Record the composite device as an attribute to the placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m     placeholder = graph_placeholder(\n\u001b[0m\u001b[1;32m   1131\u001b[0m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[1;32m   1132\u001b[0m   \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     39\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       attrs=attrs, name=name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3475\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   1975\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m   \u001b[0;31m# Add attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "best_run = None\n",
    "best_model = None\n",
    "space = None\n",
    "trials=Trials()\n",
    "best_run, best_model, space = optim.minimize(model=get_nn_hyperas_model,\n",
    "                                      data=get_data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      trials=trials,\n",
    "                                      notebook_name='regression_nn',\n",
    "                                      eval_space=True,\n",
    "                                      return_space=True,\n",
    "                                      functions=[convert_nn_params, get_regression_cv_metrics, create_and_fit_nn_regressor_with_params, build_nn_model_with_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_regression_nn(input_shape):\n",
    "#     pass\n",
    "\n",
    "# def create_and_fit_nn_regressor(X, y, X_val, y_val, patience=30, regressor_params={}):\n",
    "#     es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "#     start = time.time()\n",
    "#     model = TransformedTargetRegressor(\n",
    "#         Pipeline([\n",
    "#             ('powertransform', PowerTransformer()),\n",
    "#             ('model', KerasRegressor(build_nn_model([X_train.shape[1]], loss=losses.MeanAbsoluteError()))),\n",
    "#         ]),\n",
    "#         PowerTransformer(),\n",
    "#     ).fit(X_train.values, y_train,\n",
    "#         model__epochs=10000, \n",
    "#         model__validation_data=(X_val.values, y_val),\n",
    "#         model__verbose=0,\n",
    "#         model__batch_size=256,\n",
    "#         model__shuffle=True,\n",
    "#         model__callbacks=[es],\n",
    "#     )\n",
    "#     end = time.time()\n",
    "#     print(f'model fit time: {end - start}')\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nn_optimized = bayes_parameter_opt_nn_regression(X, y, init_round=2, opt_round=50, n_folds=10, verbose=0, patience=10, validation_size=0.05)"
   ]
  }
 ]
}